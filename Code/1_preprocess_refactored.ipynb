{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ffa062",
   "metadata": {},
   "source": [
    "# Serial Dependence in Active vs. Passive Retrieval\n",
    "\n",
    "**Analysis Pipeline: Retrieval Serial Dependence (RSD) Experiment**\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### Part I: Data Preparation\n",
    "1. **Data Loading & Preprocessing**\n",
    "   - Load PsychoPy CSV files\n",
    "   - Identify task type (color vs. orientation) and retrieval mode (active vs. passive)\n",
    "   - Extract trial information and responses\n",
    "\n",
    "2. **Data Cleaning & Quality Control**\n",
    "   - RT-based exclusion (min: 0.2s, max: 99th percentile)\n",
    "   - Response validity checks\n",
    "   - Trial count summary\n",
    "\n",
    "3. **Circular Variables Computation**\n",
    "   - Compute response error\n",
    "   - Compute serial dependence variables (\u0394s, \u0394r)\n",
    "   - Export cleaned data\n",
    "\n",
    "---\n",
    "\n",
    "### Part II: Exploratory Analysis\n",
    "4. **Data Distribution Analysis**\n",
    "   - Stimulus and response distributions\n",
    "   - Error distributions\n",
    "   - von Mises distribution fitting (for descriptive statistics)\n",
    "\n",
    "---\n",
    "\n",
    "### Part III: Serial Dependence Analysis (DoG Method)\n",
    "5. **Serial Dependence Curve Fitting**\n",
    "   - **Method**: Fischer & Whitney (2014) Derivative of Gaussian (DoG)\n",
    "   - **Formula**: `Bias(\u0394) = A\u00b7\u0394\u00b7exp(-\u0394\u00b2/2\u03c3\u00b2)`\n",
    "   - Fit curves by condition:\n",
    "     - Overall\n",
    "     - Task (Color vs. Orientation)\n",
    "     - Transition types (CC, AA, AC, etc.)\n",
    "\n",
    "6. **Statistical Comparison**\n",
    "   - Compare serial dependence strength (A parameter) across conditions\n",
    "   - Visualize results with bar plots\n",
    "   - Statistical tests\n",
    "\n",
    "---\n",
    "\n",
    "### Part IV: Results Summary\n",
    "7. **Key Findings**\n",
    "   - Task specificity\n",
    "   - Active vs. Passive retrieval effects\n",
    "   - Transition-dependent modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import i0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Set paths dynamically (works from repo root or Code folder)\n",
    "CWD = Path.cwd().resolve()\n",
    "if (CWD / \"Data\").exists():\n",
    "    ROOT = CWD\n",
    "elif CWD.name == \"Code\" and (CWD.parent / \"Data\").exists():\n",
    "    ROOT = CWD.parent\n",
    "else:\n",
    "    ROOT = CWD\n",
    "\n",
    "DATA_DIR = ROOT / \"Data\" / \"Pilot_data\"\n",
    "OUT_DIR = ROOT / \"Data\" / \"derived\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7ce40b",
   "metadata": {},
   "source": [
    "---\n",
    "# Part I: Data Preparation\n",
    "\n",
    "## 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circDiff(a, b, period):\n",
    "    \"\"\"Compute circular difference: a - b in [-period/2, period/2]\"\"\"\n",
    "    return np.mod(a - b + period / 2, period) - period / 2\n",
    "\n",
    "\n",
    "def load_psychopy_data(data_dir):\n",
    "    \"\"\"Load and merge all PsychoPy CSV files\"\"\"\n",
    "    files = sorted(data_dir.glob(\"*.csv\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files in {data_dir}\")\n",
    "    \n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        df[\"subject\"] = df[\"participant\"].astype(str)\n",
    "        df[\"source_file\"] = f.name\n",
    "        dfs.append(df)\n",
    "    \n",
    "    print(f\"Loaded {len(files)} files: {[f.name for f in files]}\")\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def identify_task_and_retrieval(df):\n",
    "    \"\"\"Identify task type and retrieval mode\n",
    "    \n",
    "    Task: color vs. orientation (inferred from response when cueType='A')\n",
    "    Retrieval: active (cueType='A', free choice) vs. passive (cueType='C'/'O', forced)\n",
    "    \"\"\"\n",
    "    # Extract task\n",
    "    df[\"task\"] = df[\"actualTask\"].astype(str).str.lower()\n",
    "    is_free = df[\"cueType\"] == \"A\"\n",
    "    df.loc[is_free & df[\"col_resp_hue\"].notna(), \"task\"] = \"color\"\n",
    "    df.loc[is_free & df[\"ori_angle\"].notna(), \"task\"] = \"orientation\"\n",
    "    \n",
    "    # Extract retrieval mode\n",
    "    df[\"retrieval_type\"] = np.where(df[\"cueType\"] == \"A\", \"active\", \"passive\")\n",
    "    \n",
    "    return df[df[\"task\"].isin([\"color\", \"orientation\"])].copy()\n",
    "\n",
    "\n",
    "# Load raw data\n",
    "raw = load_psychopy_data(DATA_DIR)\n",
    "raw[\"is_main\"] = raw[\"mainLoop.thisN\"].notna()\n",
    "raw = identify_task_and_retrieval(raw)\n",
    "\n",
    "# Extract trial info\n",
    "raw[\"block\"] = raw[\"Block_index\"].astype(\"Int64\")\n",
    "raw[\"trial\"] = raw[\"trial_in_block\"].astype(\"Int64\")\n",
    "\n",
    "# Extract stimulus, response, and RT\n",
    "raw[\"stim\"] = np.where(raw[\"task\"] == \"color\", raw[\"col_stim_hue\"], raw[\"ori_stim\"])\n",
    "raw[\"resp\"] = np.where(raw[\"task\"] == \"color\", \n",
    "                       raw[\"col_resp_hue\"], \n",
    "                       np.mod(raw[\"ori_angle\"], 180))  # Normalize orientation to [0, 180)\n",
    "raw[\"rt\"] = np.where(raw[\"task\"] == \"color\",\n",
    "                     raw[\"resp_color.stopped\"] - raw[\"Cue.stopped\"],\n",
    "                     raw[\"resp_oriation.stopped\"] - raw[\"Cue.stopped\"])\n",
    "\n",
    "print(f\"\\nTotal trials: {len(raw)} ({raw['is_main'].sum()} main trials)\")\n",
    "print(f\"\\nTask distribution:\")\n",
    "print(raw.groupby([\"subject\", \"task\"]).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_trials(df, rt_min=0.2, rt_percentile=0.99):\n",
    "    \"\"\"Exclude invalid trials based on RT and response quality\"\"\"\n",
    "    # Keep only main trials\n",
    "    df = df[df[\"is_main\"]].copy()\n",
    "\n",
    "    # Drop rows without RT or response to remove unusable records early\n",
    "    df = df[df[\"rt\"].notna() & df[\"resp\"].notna()].copy()\n",
    "\n",
    "    # Compute RT threshold per subject\n",
    "    rt_max = df.groupby(\"subject\")[\"rt\"].quantile(rt_percentile)\n",
    "    df[\"rt_max\"] = df[\"subject\"].map(rt_max)\n",
    "\n",
    "    # Exclusion criteria\n",
    "    exclude = (\n",
    "        (df[\"rt\"] < rt_min) |                                    # Too fast\n",
    "        (df[\"rt\"] > df[\"rt_max\"]) |                              # Too slow\n",
    "        df[\"resp\"].isna() |                                       # Missing response\n",
    "        (df[\"resp\"] < 0) |                                        # Invalid value\n",
    "        ((df[\"task\"] == \"color\") & (df[\"resp\"] >= 360)) |        # Out of range\n",
    "        ((df[\"task\"] == \"orientation\") & (df[\"resp\"] >= 180))    # Out of range\n",
    "    )\n",
    "\n",
    "    n_excluded = exclude.sum()\n",
    "    print(f\"Excluded {n_excluded}/{len(df)} trials ({100*n_excluded/len(df):.1f}%)\")\n",
    "\n",
    "    return df[~exclude].copy()\n",
    "\n",
    "\n",
    "# Clean trials\n",
    "df = clean_trials(raw)\n",
    "print(f\"Retained {len(df)} valid trials\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9aa2ef",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a22d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_circular_variables(df):\n",
    "    \"\"\"Compute error and serial dependence variables\n",
    "\n",
    "    Variables:\n",
    "    - error: response error (current trial)\n",
    "    - delta_s: stimulus shift (previous - current)\n",
    "    - delta_r: response shift (previous response - current stimulus)\n",
    "\n",
    "    All within subject/task/block to avoid boundary effects\n",
    "    \"\"\"\n",
    "    # Sort by subject, task, block, trial\n",
    "    df = df.sort_values([\"subject\", \"task\", \"block\", \"trial\"]).reset_index(drop=True)\n",
    "\n",
    "    # Normalize angles\n",
    "    df[\"stim_norm\"] = np.where(df[\"task\"] == \"color\",\n",
    "                               np.mod(df[\"stim\"], 360),\n",
    "                               np.mod(df[\"stim\"], 180))\n",
    "    df[\"resp_norm\"] = np.where(df[\"task\"] == \"color\",\n",
    "                               np.mod(df[\"resp\"], 360),\n",
    "                               np.mod(df[\"resp\"], 180))\n",
    "\n",
    "    # Compute error\n",
    "    period = np.where(df[\"task\"] == \"color\", 360, 180)\n",
    "    df[\"error\"] = circDiff(df[\"resp_norm\"], df[\"stim_norm\"], period)\n",
    "\n",
    "    # Lag variables (within subject/task/block)\n",
    "    group_keys = [\"subject\", \"task\", \"block\"]\n",
    "    df[\"stim_prev\"] = df.groupby(group_keys)[\"stim_norm\"].shift(1)\n",
    "    df[\"resp_prev\"] = df.groupby(group_keys)[\"resp_norm\"].shift(1)\n",
    "\n",
    "    # Serial dependence variables\n",
    "    df[\"delta_s\"] = circDiff(df[\"stim_prev\"], df[\"stim_norm\"], period)\n",
    "    df[\"delta_r\"] = circDiff(df[\"resp_prev\"], df[\"stim_norm\"], period)\n",
    "    df[\"has_lag\"] = df[\"stim_prev\"].notna()\n",
    "\n",
    "    # Remove rows with unusable lag metrics\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    valid = df.dropna(subset=[\"delta_s\", \"delta_r\", \"error\"])\n",
    "    print(f\"Trials with lag variables: {valid['has_lag'].sum()}/{len(valid)} ({100*valid['has_lag'].mean():.1f}%)\")\n",
    "\n",
    "    return valid\n",
    "\n",
    "\n",
    "# Compute circular variables\n",
    "df = compute_circular_variables(df)\n",
    "\n",
    "# Export cleaned data for downstream analyses\n",
    "out_cols = [\"subject\", \"task\", \"retrieval_type\", \"block\", \"trial\",\n",
    "            \"stim\", \"resp\", \"rt\", \"error\", \"delta_s\", \"delta_r\", \"has_lag\"]\n",
    "df[[c for c in out_cols if c in df.columns]].to_csv(OUT_DIR / \"trials_cleaned.csv\", index=False)\n",
    "print(f\"\n",
    "Saved: {OUT_DIR / 'trials_cleaned.csv'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85138265",
   "metadata": {},
   "source": [
    "## 3. Circular Variables Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import vonmises, circmean, circstd\n",
    "\n",
    "def fit_vonmises(data_degrees, scale=1.0):\n",
    "    \"\"\"Fit von Mises distribution to circular data\n",
    "    \n",
    "    Args:\n",
    "        data_degrees: Angular data in degrees\n",
    "        scale: Scale factor (360 for color, 180 for orientation)\n",
    "    \n",
    "    Returns:\n",
    "        mu: Mean direction (radians)\n",
    "        kappa: Concentration parameter\n",
    "        mu_deg: Mean direction (degrees)\n",
    "    \"\"\"\n",
    "    # Convert to radians and scale to [0, 2\u03c0]\n",
    "    data_rad = np.deg2rad(data_degrees) * (360 / scale)\n",
    "    \n",
    "    # Compute circular mean and resultant vector length\n",
    "    mu = circmean(data_rad, high=2*np.pi, low=0)\n",
    "    R = np.abs(np.mean(np.exp(1j * data_rad)))\n",
    "    \n",
    "    # Estimate kappa (concentration parameter)\n",
    "    # Using approximation: kappa \u2248 R * (2 - R\u00b2) / (1 - R\u00b2) for R < 0.85\n",
    "    if R < 0.85:\n",
    "        kappa = R * (2 - R**2) / (1 - R**2)\n",
    "    else:\n",
    "        # Better approximation for large R\n",
    "        kappa = 1 / (2 * (1 - R))\n",
    "    \n",
    "    mu_deg = np.rad2deg(mu) * (scale / 360)\n",
    "    \n",
    "    return mu, kappa, mu_deg\n",
    "\n",
    "\n",
    "# Visualize stimulus, response, and error distributions for both tasks\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Color task distributions\n",
    "color_data = df[df[\"task\"] == \"color\"]\n",
    "ori_data = df[df[\"task\"] == \"orientation\"]\n",
    "\n",
    "# Row 1: Color task\n",
    "# Stimulus distribution with von Mises fit\n",
    "ax = axes[0, 0]\n",
    "counts, bins, _ = ax.hist(color_data[\"stim_norm\"], bins=36, range=(0, 360), \n",
    "                          color=\"steelblue\", alpha=0.6, edgecolor=\"black\", density=True)\n",
    "# Fit von Mises\n",
    "mu_stim, kappa_stim, mu_stim_deg = fit_vonmises(color_data[\"stim_norm\"], scale=360)\n",
    "x = np.linspace(0, 360, 360)\n",
    "x_rad = np.deg2rad(x)\n",
    "vm_pdf = vonmises.pdf(x_rad, kappa_stim, loc=mu_stim) * (2*np.pi/360)\n",
    "ax.plot(x, vm_pdf, 'r-', linewidth=2.5, label=f'von Mises: \u03bc={mu_stim_deg:.1f}\u00b0, \u03ba={kappa_stim:.2f}')\n",
    "ax.set_xlabel(\"Stimulus (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Density\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(f\"Color: Stimulus Distribution (N={len(color_data)})\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(0, 360)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Response distribution with von Mises fit\n",
    "ax = axes[0, 1]\n",
    "counts, bins, _ = ax.hist(color_data[\"resp_norm\"], bins=36, range=(0, 360), \n",
    "                          color=\"coral\", alpha=0.6, edgecolor=\"black\", density=True)\n",
    "# Fit von Mises\n",
    "mu_resp, kappa_resp, mu_resp_deg = fit_vonmises(color_data[\"resp_norm\"], scale=360)\n",
    "vm_pdf = vonmises.pdf(x_rad, kappa_resp, loc=mu_resp) * (2*np.pi/360)\n",
    "ax.plot(x, vm_pdf, 'r-', linewidth=2.5, label=f'von Mises: \u03bc={mu_resp_deg:.1f}\u00b0, \u03ba={kappa_resp:.2f}')\n",
    "ax.set_xlabel(\"Response (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Density\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(f\"Color: Response Distribution (N={len(color_data)})\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(0, 360)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Error distribution with von Mises fit (centered at 0)\n",
    "ax = axes[0, 2]\n",
    "counts, bins, _ = ax.hist(color_data[\"error\"], bins=36, range=(-180, 180), \n",
    "                          color=\"lightgreen\", alpha=0.6, edgecolor=\"black\", density=True)\n",
    "ax.axvline(0, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.7)\n",
    "# Fit von Mises to error (shifted to [0, 360] for fitting)\n",
    "error_shifted = np.mod(color_data[\"error\"] + 180, 360)\n",
    "mu_err, kappa_err, _ = fit_vonmises(error_shifted, scale=360)\n",
    "x_err = np.linspace(-180, 180, 360)\n",
    "x_err_rad = np.deg2rad(x_err + 180)\n",
    "vm_pdf_err = vonmises.pdf(x_err_rad, kappa_err, loc=mu_err) * (2*np.pi/360)\n",
    "ax.plot(x_err, vm_pdf_err, 'r-', linewidth=2.5, \n",
    "        label=f'von Mises: \u03ba={kappa_err:.2f}\\nMean={color_data[\"error\"].mean():.2f}\u00b0')\n",
    "ax.set_xlabel(\"Error (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Density\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(f\"Color: Error Distribution (von Mises Fit)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(-180, 180)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 2D scatter: Stimulus vs Response\n",
    "ax = axes[0, 3]\n",
    "scatter = ax.scatter(color_data[\"stim_norm\"], color_data[\"resp_norm\"], \n",
    "                    c=np.abs(color_data[\"error\"]), cmap=\"YlOrRd\", \n",
    "                    alpha=0.5, s=20, edgecolors=\"black\", linewidth=0.5)\n",
    "ax.plot([0, 360], [0, 360], \"k--\", linewidth=2, label=\"Perfect match\")\n",
    "ax.set_xlabel(\"Stimulus (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Response (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(\"Color: Stimulus vs Response\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(0, 360)\n",
    "ax.set_ylim(0, 360)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label(\"Absolute Error\", fontsize=10)\n",
    "\n",
    "# Row 2: Orientation task (180\u00b0 periodicity)\n",
    "# Stimulus distribution with von Mises fit\n",
    "ax = axes[1, 0]\n",
    "counts, bins, _ = ax.hist(ori_data[\"stim_norm\"], bins=18, range=(0, 180), \n",
    "                          color=\"steelblue\", alpha=0.6, edgecolor=\"black\", density=True)\n",
    "# Fit von Mises (double angle for 180\u00b0 periodicity)\n",
    "ori_stim_doubled = np.mod(ori_data[\"stim_norm\"] * 2, 360)\n",
    "mu_stim_ori, kappa_stim_ori, _ = fit_vonmises(ori_stim_doubled, scale=360)\n",
    "x_ori = np.linspace(0, 180, 180)\n",
    "x_ori_rad = np.deg2rad(x_ori * 2)\n",
    "vm_pdf_ori = vonmises.pdf(x_ori_rad, kappa_stim_ori, loc=mu_stim_ori) * (4*np.pi/360)\n",
    "ax.plot(x_ori, vm_pdf_ori, 'r-', linewidth=2.5, \n",
    "        label=f'von Mises (2\u03b8): \u03ba={kappa_stim_ori:.2f}')\n",
    "ax.set_xlabel(\"Stimulus (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Density\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(f\"Orientation: Stimulus Distribution (N={len(ori_data)})\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(0, 180)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Response distribution with von Mises fit\n",
    "ax = axes[1, 1]\n",
    "counts, bins, _ = ax.hist(ori_data[\"resp_norm\"], bins=18, range=(0, 180), \n",
    "                          color=\"coral\", alpha=0.6, edgecolor=\"black\", density=True)\n",
    "# Fit von Mises (double angle)\n",
    "ori_resp_doubled = np.mod(ori_data[\"resp_norm\"] * 2, 360)\n",
    "mu_resp_ori, kappa_resp_ori, _ = fit_vonmises(ori_resp_doubled, scale=360)\n",
    "vm_pdf_ori_resp = vonmises.pdf(x_ori_rad, kappa_resp_ori, loc=mu_resp_ori) * (4*np.pi/360)\n",
    "ax.plot(x_ori, vm_pdf_ori_resp, 'r-', linewidth=2.5, \n",
    "        label=f'von Mises (2\u03b8): \u03ba={kappa_resp_ori:.2f}')\n",
    "ax.set_xlabel(\"Response (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Density\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(f\"Orientation: Response Distribution (N={len(ori_data)})\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(0, 180)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Error distribution with von Mises fit\n",
    "ax = axes[1, 2]\n",
    "counts, bins, _ = ax.hist(ori_data[\"error\"], bins=18, range=(-90, 90), \n",
    "                          color=\"lightgreen\", alpha=0.6, edgecolor=\"black\", density=True)\n",
    "ax.axvline(0, color=\"red\", linestyle=\"--\", linewidth=2, alpha=0.7)\n",
    "# Fit von Mises to error (shifted to [0, 180] for fitting, double angle)\n",
    "error_ori_shifted = np.mod(ori_data[\"error\"] + 90, 180) * 2\n",
    "mu_err_ori, kappa_err_ori, _ = fit_vonmises(error_ori_shifted, scale=360)\n",
    "x_err_ori = np.linspace(-90, 90, 180)\n",
    "x_err_ori_rad = np.deg2rad((x_err_ori + 90) * 2)\n",
    "vm_pdf_err_ori = vonmises.pdf(x_err_ori_rad, kappa_err_ori, loc=mu_err_ori) * (4*np.pi/360)\n",
    "ax.plot(x_err_ori, vm_pdf_err_ori, 'r-', linewidth=2.5, \n",
    "        label=f'von Mises (2\u03b8): \u03ba={kappa_err_ori:.2f}\\nMean={ori_data[\"error\"].mean():.2f}\u00b0')\n",
    "ax.set_xlabel(\"Error (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Density\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(f\"Orientation: Error Distribution (von Mises Fit)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(-90, 90)\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 2D scatter: Stimulus vs Response\n",
    "ax = axes[1, 3]\n",
    "scatter = ax.scatter(ori_data[\"stim_norm\"], ori_data[\"resp_norm\"], \n",
    "                    c=np.abs(ori_data[\"error\"]), cmap=\"YlOrRd\", \n",
    "                    alpha=0.5, s=20, edgecolors=\"black\", linewidth=0.5)\n",
    "ax.plot([0, 180], [0, 180], \"k--\", linewidth=2, label=\"Perfect match\")\n",
    "ax.set_xlabel(\"Stimulus (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Response (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(\"Orientation: Stimulus vs Response\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlim(0, 180)\n",
    "ax.set_ylim(0, 180)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label(\"Absolute Error\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"data_distributions.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved: {OUT_DIR / 'data_distributions.png'}\")\n",
    "\n",
    "# Print summary statistics with von Mises parameters\n",
    "print(\"\\n=== Distribution Summary with von Mises Parameters ===\")\n",
    "print(f\"\\nColor Task (N={len(color_data)}):\")\n",
    "print(f\"  Stimulus: \u03bc={mu_stim_deg:.1f}\u00b0, \u03ba={kappa_stim:.2f} (range: [{color_data['stim_norm'].min():.1f}, {color_data['stim_norm'].max():.1f}]\u00b0)\")\n",
    "print(f\"  Response: \u03bc={mu_resp_deg:.1f}\u00b0, \u03ba={kappa_resp:.2f} (range: [{color_data['resp_norm'].min():.1f}, {color_data['resp_norm'].max():.1f}]\u00b0)\")\n",
    "print(f\"  Error: \u03ba={kappa_err:.2f}, Mean={color_data['error'].mean():.2f}\u00b0, SD={color_data['error'].std():.2f}\u00b0\")\n",
    "print(f\"  |Error|: Mean={np.abs(color_data['error']).mean():.2f}\u00b0, Median={np.abs(color_data['error']).median():.2f}\u00b0\")\n",
    "print(f\"  von Mises concentration \u03ba interpretation:\")\n",
    "print(f\"    \u03ba < 1: very dispersed (uniform-like)\")\n",
    "print(f\"    \u03ba \u2248 1-2: moderately dispersed\")\n",
    "print(f\"    \u03ba > 2: concentrated around mean\")\n",
    "\n",
    "print(f\"\\nOrientation Task (N={len(ori_data)}) [180\u00b0 periodicity, using 2\u03b8]:\")\n",
    "print(f\"  Stimulus (2\u03b8): \u03ba={kappa_stim_ori:.2f} (range: [{ori_data['stim_norm'].min():.1f}, {ori_data['stim_norm'].max():.1f}]\u00b0)\")\n",
    "print(f\"  Response (2\u03b8): \u03ba={kappa_resp_ori:.2f} (range: [{ori_data['resp_norm'].min():.1f}, {ori_data['resp_norm'].max():.1f}]\u00b0)\")\n",
    "print(f\"  Error (2\u03b8): \u03ba={kappa_err_ori:.2f}, Mean={ori_data['error'].mean():.2f}\u00b0, SD={ori_data['error'].std():.2f}\u00b0\")\n",
    "print(f\"  |Error|: Mean={np.abs(ori_data['error']).mean():.2f}\u00b0, Median={np.abs(ori_data['error']).median():.2f}\u00b0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a53f8",
   "metadata": {},
   "source": [
    "---\n",
    "# Part II: Exploratory Analysis\n",
    "\n",
    "## 4. Data Distribution Analysis (Descriptive Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f36ed0",
   "metadata": {},
   "source": [
    "---\n",
    "# Part III: Serial Dependence Analysis\n",
    "\n",
    "## 5. DoG Curve Fitting (Fischer & Whitney 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f1ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute transitions for condition-wise analysis\n",
    "def compute_transition_types(df):\n",
    "    \"\"\"Compute trial-to-trial transition types\n",
    "\n",
    "    Codes: AA (Active\u2192Active), AC (Active\u2192Color), CC (Color\u2192Color), etc.\n",
    "    A = Active (free choice)\n",
    "    C = Color task (forced)\n",
    "    O = Orientation task (forced)\n",
    "    \"\"\"\n",
    "    df = df.sort_values([\"subject\", \"task\", \"block\", \"trial\"]).reset_index(drop=True)\n",
    "\n",
    "    # Get previous trial's retrieval type\n",
    "    group_keys = [\"subject\", \"task\", \"block\"]\n",
    "    df[\"retrieval_prev\"] = df.groupby(group_keys)[\"retrieval_type\"].shift(1)\n",
    "\n",
    "    def get_code(row):\n",
    "        if pd.isna(row[\"retrieval_prev\"]):\n",
    "            return np.nan\n",
    "\n",
    "        # Previous trial code\n",
    "        prev = \"A\" if row[\"retrieval_prev\"] == \"active\" else (\"C\" if row[\"task\"] == \"color\" else \"O\")\n",
    "        # Current trial code\n",
    "        curr = \"A\" if row[\"retrieval_type\"] == \"active\" else (\"C\" if row[\"task\"] == \"color\" else \"O\")\n",
    "\n",
    "        return prev + curr\n",
    "\n",
    "    df[\"transition\"] = df.apply(get_code, axis=1)\n",
    "    return df[df[\"transition\"].notna()].copy()\n",
    "\n",
    "# Prepare data with transitions\n",
    "serial_df = df[df[\"has_lag\"]].copy()\n",
    "data_trans = compute_transition_types(serial_df)\n",
    "\n",
    "print(f\"\n",
    "=== Transition Counts ===\")\n",
    "print(data_trans[\"transition\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_derivative(delta, A, sigma):\n",
    "    \"\"\"Derivative of Gaussian (DoG) for serial dependence\n",
    "    \n",
    "    Classic formula from Fischer & Whitney (2014):\n",
    "    Bias(\u0394) = A \u00b7 \u0394 \u00b7 exp(-\u0394\u00b2 / 2\u03c3\u00b2)\n",
    "    \n",
    "    Parameters:\n",
    "    - A: Amplitude coefficient (dimensionless, typically 0.001-0.01)\n",
    "    - sigma (\u03c3): Tuning width in degrees (typically 20-60\u00b0)\n",
    "    \n",
    "    Properties:\n",
    "    - A > 0: Attraction (response pulled toward previous stimulus)\n",
    "    - Peak at \u0394 = \u00b1\u03c3: peak bias = A\u00b7\u03c3/\u221ae \u2248 0.606\u00b7A\u00b7\u03c3\n",
    "    - For A=0.005, \u03c3=30\u00b0: peak bias \u2248 0.091\u00b0 (reasonable)\n",
    "    \"\"\"\n",
    "    return A * delta * np.exp(-delta**2 / (2 * sigma**2))\n",
    "\n",
    "\n",
    "def compute_folded_error(df):\n",
    "    \"\"\"Compute folded error: e' = error \u00d7 sign(\u0394s)\n",
    "    \n",
    "    This is the standard serial dependence metric:\n",
    "    - e' > 0: Attraction (response toward previous stimulus)\n",
    "    - e' < 0: Repulsion (response away from previous)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"error_folded\"] = df[\"error\"] * np.sign(df[\"delta_s\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def fit_dog_derivative(x_data, y_data):\n",
    "    \"\"\"Fit DoG derivative to binned data\"\"\"\n",
    "    try:\n",
    "        # Initial guess\n",
    "        # A is dimensionless coefficient (typ. 0.001-0.01 for reasonable bias)\n",
    "        # \u03c3 is tuning width in degrees (typ. 20-60\u00b0)\n",
    "        A_init = 0.005  # Start with moderate attraction\n",
    "        sigma_init = 30.0  # Start with ~30\u00b0 tuning width\n",
    "        \n",
    "        initial_guess = [A_init, sigma_init]\n",
    "        \n",
    "        # Bounds: A in [-0.02, 0.02] (dimensionless), sigma in [5, 120] degrees\n",
    "        # With A=0.01, \u03c3=30\u00b0: peak bias = 0.01\u00d730/\u221ae \u2248 0.18\u00b0 (reasonable)\n",
    "        popt, _ = curve_fit(dog_derivative, x_data, y_data, \n",
    "                           p0=initial_guess,\n",
    "                           maxfev=10000, \n",
    "                           bounds=([-0.02, 5], [0.02, 120]))\n",
    "        \n",
    "        # Compute R\u00b2\n",
    "        y_pred = dog_derivative(x_data, *popt)\n",
    "        ss_res = np.sum((y_data - y_pred)**2)\n",
    "        ss_tot = np.sum((y_data - np.mean(y_data))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        \n",
    "        return popt, r2, True\n",
    "    except Exception as e:\n",
    "        print(f\"Fitting failed: {e}\")\n",
    "        return None, None, False\n",
    "\n",
    "\n",
    "def bin_and_fit_dog(data, condition_name, bin_width=15, max_range=180, min_trials=5):\n",
    "    \"\"\"Bin data by delta_s and fit DoG derivative curve\"\"\"\n",
    "    if len(data) < 20:\n",
    "        return None\n",
    "    \n",
    "    # Compute folded error\n",
    "    data = compute_folded_error(data)\n",
    "    \n",
    "    # Create symmetric bins from -max_range to +max_range\n",
    "    bins = np.arange(-max_range, max_range + bin_width, bin_width)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    # Bin data\n",
    "    data = data.copy()\n",
    "    data[\"bin\"] = pd.cut(data[\"delta_s\"], bins=bins, labels=bin_centers, include_lowest=True)\n",
    "    binned = data.groupby(\"bin\", observed=True).agg({\n",
    "        \"error_folded\": [\"mean\", \"sem\", \"count\"]\n",
    "    }).reset_index()\n",
    "    binned.columns = [\"delta_s\", \"mean_error_folded\", \"sem_error\", \"count\"]\n",
    "    binned[\"delta_s\"] = binned[\"delta_s\"].astype(float)\n",
    "    binned = binned[binned[\"count\"] >= min_trials]\n",
    "    \n",
    "    if len(binned) < 4:\n",
    "        return None\n",
    "    \n",
    "    # Fit DoG derivative\n",
    "    x_data = binned[\"delta_s\"].values\n",
    "    y_data = binned[\"mean_error_folded\"].values\n",
    "    popt, r2, success = fit_dog_derivative(x_data, y_data)\n",
    "    \n",
    "    return {\n",
    "        \"condition\": condition_name,\n",
    "        \"binned\": binned,\n",
    "        \"params\": popt,\n",
    "        \"r2\": r2,\n",
    "        \"success\": success,\n",
    "        \"n_trials\": len(data)\n",
    "    }\n",
    "\n",
    "\n",
    "# Define conditions for DoG fitting\n",
    "conditions = [\n",
    "    (\"Overall\", data_trans, 20, 180),\n",
    "    (\"Color Task\", data_trans[data_trans[\"task\"] == \"color\"], 20, 180),\n",
    "    (\"Orientation Task\", data_trans[data_trans[\"task\"] == \"orientation\"], 15, 90),\n",
    "    (\"CC (Color\u2192Color)\", data_trans[data_trans[\"transition\"] == \"CC\"], 20, 180),\n",
    "    (\"AA (Active\u2192Active)\", data_trans[data_trans[\"transition\"] == \"AA\"], 15, 90),\n",
    "    (\"AC (Active\u2192Color)\", data_trans[data_trans[\"transition\"] == \"AC\"], 20, 180),\n",
    "]\n",
    "\n",
    "# Fit DoG derivative curves\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, data, bin_w, max_r) in enumerate(conditions):\n",
    "    ax = axes[idx]\n",
    "    result = bin_and_fit_dog(data, name, bin_width=bin_w, max_range=max_r)\n",
    "    \n",
    "    if result is None:\n",
    "        ax.text(0.5, 0.5, f\"{name}\\n(Insufficient data)\", \n",
    "                ha=\"center\", va=\"center\", transform=ax.transAxes, fontsize=10)\n",
    "        ax.set_xlabel(\"\u0394s (degrees)\")\n",
    "        ax.set_ylabel(\"Folded Error (degrees)\")\n",
    "        ax.set_xlim(-max_r, max_r)\n",
    "        continue\n",
    "    \n",
    "    binned = result[\"binned\"]\n",
    "    \n",
    "    # Plot binned data\n",
    "    ax.errorbar(binned[\"delta_s\"], binned[\"mean_error_folded\"], yerr=binned[\"sem_error\"],\n",
    "                fmt=\"o\", color=\"steelblue\", alpha=0.7, markersize=8, capsize=5, \n",
    "                linewidth=2, label=\"Data\", zorder=3)\n",
    "    \n",
    "    # Plot DoG fit\n",
    "    if result[\"success\"]:\n",
    "        x_fit = np.linspace(-max_r, max_r, 360)\n",
    "        y_fit = dog_derivative(x_fit, *result[\"params\"])\n",
    "        ax.plot(x_fit, y_fit, \"r-\", linewidth=3, alpha=0.9, label=\"DoG derivative fit\", zorder=2)\n",
    "        \n",
    "        # Add parameters\n",
    "        A, sigma = result[\"params\"]\n",
    "        bias_type = \"Attraction\" if A > 0 else \"Repulsion\"\n",
    "        peak_location = sigma  # Peak at \u0394 = \u00b1\u03c3\n",
    "        peak_bias = dog_derivative(sigma, A, sigma)  # Bias magnitude at peak \u2248 0.606\u00b7A\u00b7\u03c3\n",
    "        \n",
    "        param_text = (f\"{bias_type}\\n\"\n",
    "                     f\"A = {A:.5f} (coef.)\\n\"\n",
    "                     f\"\u03c3 = {sigma:.1f}\u00b0 (width)\\n\"\n",
    "                     f\"Peak at \u00b1{peak_location:.1f}\u00b0\\n\"\n",
    "                     f\"Peak bias = {peak_bias:.2f}\u00b0\\n\"\n",
    "                     f\"R\u00b2 = {result['r2']:.3f}\")\n",
    "        ax.text(0.02, 0.98, param_text, transform=ax.transAxes, fontsize=9,\n",
    "               va=\"top\", ha=\"left\", \n",
    "               bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.85, edgecolor=\"black\"))\n",
    "    \n",
    "    ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.6, zorder=1)\n",
    "    ax.axvline(0, color=\"gray\", linestyle=\"--\", linewidth=1.5, alpha=0.6, zorder=1)\n",
    "    ax.set_xlabel(\"\u0394s (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Folded Error e' (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_title(f\"{name} (N={result['n_trials']})\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_xlim(-max_r, max_r)\n",
    "    ax.legend(loc=\"upper left\", fontsize=10, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"dog_serial_dependence.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved: {OUT_DIR / 'dog_serial_dependence.png'}\")\n",
    "\n",
    "# Print fitting results\n",
    "print(\"\\n=== DoG Derivative Fitting Results (Fischer & Whitney 2014 method) ===\")\n",
    "print(\"Formula: Bias(\u0394) = A\u00b7\u0394\u00b7exp(-\u0394\u00b2/2\u03c3\u00b2)\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  A: Amplitude coefficient (dimensionless, typ. 0.001-0.02)\")\n",
    "print(\"  \u03c3: Tuning width in degrees (peak at \u00b1\u03c3)\")\n",
    "print(\"  Peak bias \u2248 0.606\u00b7A\u00b7\u03c3 degrees\")\n",
    "print(\"  A > 0: Attraction toward previous stimulus\\n\")\n",
    "\n",
    "for name, data, bin_w, max_r in conditions:\n",
    "    result = bin_and_fit_dog(data, name, bin_width=bin_w, max_range=max_r)\n",
    "    if result and result[\"success\"]:\n",
    "        A, sigma = result[\"params\"]\n",
    "        peak_bias = dog_derivative(sigma, A, sigma)\n",
    "        bias_type = \"Attraction\" if A > 0 else \"Repulsion\"\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  A = {A:.4f} ({bias_type})\")\n",
    "        print(f\"  \u03c3 = {sigma:.1f}\u00b0 (tuning width)\")\n",
    "        print(f\"  Peak bias = {peak_bias:.2f}\u00b0 at \u0394s = \u00b1{sigma:.1f}\u00b0\")\n",
    "        print(f\"  R\u00b2 = {result['r2']:.3f}\")\n",
    "        \n",
    "        if peak_bias > 1.0:\n",
    "            print(f\"  \u2192 Strong attraction: {peak_bias:.2f}\u00b0 bias at {sigma:.0f}\u00b0 distance\")\n",
    "        elif peak_bias > 0.2:\n",
    "            print(f\"  \u2192 Moderate attraction: {peak_bias:.2f}\u00b0 bias\")\n",
    "        else:\n",
    "            print(f\"  \u2192 Weak/no serial dependence: {peak_bias:.2f}\u00b0 bias\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736cf03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract DoG parameters for all conditions\n",
    "dog_results = []\n",
    "\n",
    "conditions_analysis = [\n",
    "    (\"Overall\", data_trans),\n",
    "    (\"Color Task\", data_trans[data_trans[\"task\"] == \"color\"]),\n",
    "    (\"Orientation Task\", data_trans[data_trans[\"task\"] == \"orientation\"]),\n",
    "    (\"Active Retrieval\", data_trans[data_trans[\"retrieval_type\"] == \"active\"]),\n",
    "    (\"Passive Retrieval\", data_trans[data_trans[\"retrieval_type\"] == \"passive\"]),\n",
    "    (\"CC (Color\u2192Color)\", data_trans[data_trans[\"transition\"] == \"CC\"]),\n",
    "    (\"AA (Active\u2192Active)\", data_trans[data_trans[\"transition\"] == \"AA\"]),\n",
    "    (\"AC (Active\u2192Color)\", data_trans[data_trans[\"transition\"] == \"AC\"]),\n",
    "    (\"CA (Color\u2192Active)\", data_trans[data_trans[\"transition\"] == \"CA\"]),\n",
    "]\n",
    "\n",
    "print(\"\\n=== DoG Fitting: Serial Dependence Strength (A Parameter) ===\\n\")\n",
    "\n",
    "for name, data in conditions_analysis:\n",
    "    # Determine appropriate range\n",
    "    if \"Orientation\" in name or \"AA\" in name or \"CA\" in name:\n",
    "        bin_w, max_r = 15, 90\n",
    "    else:\n",
    "        bin_w, max_r = 20, 180\n",
    "    \n",
    "    result = bin_and_fit_dog(data, name, bin_width=bin_w, max_range=max_r)\n",
    "    \n",
    "    if result and result[\"success\"]:\n",
    "        A, sigma = result[\"params\"]\n",
    "        peak_bias = dog_derivative(sigma, A, sigma)\n",
    "        \n",
    "        dog_results.append({\n",
    "            \"condition\": name,\n",
    "            \"n_trials\": result[\"n_trials\"],\n",
    "            \"A\": A,\n",
    "            \"sigma\": sigma,\n",
    "            \"peak_bias\": peak_bias,\n",
    "            \"r2\": result[\"r2\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  N = {result['n_trials']}, A = {A:.4f}, \u03c3 = {sigma:.1f}\u00b0, Peak = {peak_bias:.2f}\u00b0, R\u00b2 = {result['r2']:.3f}\")\n",
    "    else:\n",
    "        print(f\"{name}: Insufficient data or fitting failed\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "dog_df = pd.DataFrame(dog_results)\n",
    "dog_df.to_csv(OUT_DIR / \"dog_parameters.csv\", index=False)\n",
    "print(f\"\\n\u2713 Saved: {OUT_DIR / 'dog_parameters.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Von Mises-based serial dependence analysis\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "def vonmises_serial(delta_deg, amplitude, mu_deg, kappa):\n",
    "    \"\"\"Von Mises shaped tuning curve for serial dependence.\"\"\"\n",
    "    delta_rad = np.deg2rad(delta_deg)\n",
    "    mu_rad = np.deg2rad(mu_deg)\n",
    "    return amplitude * np.sin(delta_rad - mu_rad) * np.exp(kappa * np.cos(delta_rad - mu_rad)) / i0(kappa)\n",
    "\n",
    "\n",
    "def fit_vonmises_serial(x_data, y_data):\n",
    "    \"\"\"Fit von Mises tuning curve to folded errors.\"\"\"\n",
    "    try:\n",
    "        amplitude_init = float(np.nanmedian(np.abs(y_data))) if len(y_data) else 0.1\n",
    "        amplitude_init = max(amplitude_init, 0.05)\n",
    "        initial = [amplitude_init, 0.0, 1.0]\n",
    "        bounds = ([-5.0, -90.0, 0.05], [5.0, 90.0, 10.0])\n",
    "\n",
    "        popt, _ = curve_fit(vonmises_serial, x_data, y_data,\n",
    "                           p0=initial, bounds=bounds, maxfev=20000)\n",
    "\n",
    "        y_pred = vonmises_serial(x_data, *popt)\n",
    "        ss_res = np.sum((y_data - y_pred)**2)\n",
    "        ss_tot = np.sum((y_data - np.mean(y_data))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        return popt, r2, True\n",
    "    except (RuntimeError, ValueError, LinAlgError) as e:\n",
    "        print(f\"Von Mises fit failed: {e}\")\n",
    "        return None, None, False\n",
    "\n",
    "\n",
    "def bin_and_fit_vonmises(data, condition_name, bin_width=20, max_range=180, min_trials=5):\n",
    "    \"\"\"Bin by \u0394s and fit a von Mises tuning curve.\"\"\"\n",
    "    if len(data) < 20:\n",
    "        return None\n",
    "\n",
    "    data = compute_folded_error(data)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"delta_s\", \"error_folded\"])\n",
    "\n",
    "    bins = np.arange(-max_range, max_range + bin_width, bin_width)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    data[\"bin\"] = pd.cut(data[\"delta_s\"], bins=bins, labels=bin_centers, include_lowest=True)\n",
    "    binned = data.groupby(\"bin\", observed=True).agg({\"error_folded\": [\"mean\", \"sem\", \"count\"]}).reset_index()\n",
    "    binned.columns = [\"delta_s\", \"mean_error_folded\", \"sem_error\", \"count\"]\n",
    "    binned[\"delta_s\"] = binned[\"delta_s\"].astype(float)\n",
    "    binned = binned[binned[\"count\"] >= min_trials]\n",
    "\n",
    "    if len(binned) < 4:\n",
    "        return None\n",
    "\n",
    "    x_data = binned[\"delta_s\"].values\n",
    "    y_data = binned[\"mean_error_folded\"].values\n",
    "    popt, r2, success = fit_vonmises_serial(x_data, y_data)\n",
    "\n",
    "    return {\n",
    "        \"condition\": condition_name,\n",
    "        \"binned\": binned,\n",
    "        \"params\": popt,\n",
    "        \"r2\": r2,\n",
    "        \"success\": success,\n",
    "        \"n_trials\": len(data)\n",
    "    }\n",
    "\n",
    "\n",
    "# Conditions to evaluate with von Mises fits\n",
    "vm_conditions = [\n",
    "    (\"Overall\", data_trans, 20, 180),\n",
    "    (\"Color Task\", data_trans[data_trans[\"task\"] == \"color\"], 20, 180),\n",
    "    (\"Orientation Task\", data_trans[data_trans[\"task\"] == \"orientation\"], 15, 90),\n",
    "    (\"Active Retrieval\", data_trans[data_trans[\"retrieval_type\"] == \"active\"], 20, 180),\n",
    "    (\"Passive Retrieval\", data_trans[data_trans[\"retrieval_type\"] == \"passive\"], 20, 180),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "vm_results = []\n",
    "\n",
    "for idx, (name, data, bin_w, max_r) in enumerate(vm_conditions):\n",
    "    ax = axes[idx]\n",
    "    result = bin_and_fit_vonmises(data, name, bin_width=bin_w, max_range=max_r)\n",
    "\n",
    "    if not result:\n",
    "        ax.set_title(f\"{name}: insufficient data\")\n",
    "        ax.axis(\"off\")\n",
    "        continue\n",
    "\n",
    "    binned = result[\"binned\"]\n",
    "    ax.errorbar(binned[\"delta_s\"], binned[\"mean_error_folded\"], yerr=binned[\"sem_error\"],\n",
    "                fmt=\"o\", color=\"darkslateblue\", alpha=0.8, markersize=8, capsize=5,\n",
    "                linewidth=2, label=\"Data\", zorder=3)\n",
    "\n",
    "    if result[\"success\"] and result[\"params\"] is not None:\n",
    "        amp, mu_deg, kappa = result[\"params\"]\n",
    "        x_fit = np.linspace(-max_r, max_r, 360)\n",
    "        y_fit = vonmises_serial(x_fit, amp, mu_deg, kappa)\n",
    "        ax.plot(x_fit, y_fit, \"crimson\", linewidth=3, alpha=0.9, label=\"Von Mises fit\", zorder=2)\n",
    "\n",
    "        peak_bias = y_fit[np.argmax(np.abs(y_fit))]\n",
    "        param_text = (f\"amp = {amp:.3f}\u00b0\n",
    "\"\n",
    "                      f\"\u03bc = {mu_deg:.1f}\u00b0\n",
    "\"\n",
    "                      f\"\u03ba = {kappa:.2f}\n",
    "\"\n",
    "                      f\"Peak bias = {peak_bias:.2f}\u00b0\n",
    "\"\n",
    "                      f\"R\u00b2 = {result['r2']:.3f}\")\n",
    "        ax.text(0.02, 0.98, param_text, transform=ax.transAxes, fontsize=9,\n",
    "                va=\"top\", ha=\"left\", bbox=dict(boxstyle=\"round\", facecolor=\"lavender\", alpha=0.9, edgecolor=\"black\"))\n",
    "\n",
    "        vm_results.append({\n",
    "            \"condition\": name,\n",
    "            \"n_trials\": result[\"n_trials\"],\n",
    "            \"amplitude\": amp,\n",
    "            \"mu\": mu_deg,\n",
    "            \"kappa\": kappa,\n",
    "            \"peak_bias\": peak_bias,\n",
    "            \"r2\": result['r2']\n",
    "        })\n",
    "\n",
    "    ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1.2, alpha=0.6, zorder=1)\n",
    "    ax.axvline(0, color=\"gray\", linestyle=\"--\", linewidth=1.2, alpha=0.6, zorder=1)\n",
    "    ax.set_xlabel(\"\u0394s (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Folded Error e' (degrees)\", fontsize=11, fontweight=\"bold\")\n",
    "    ax.set_title(f\"{name} (N={result['n_trials']})\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.set_xlim(-max_r, max_r)\n",
    "    ax.legend(loc=\"upper left\", fontsize=9, framealpha=0.9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplot if any\n",
    "for ax in axes[len(vm_conditions):]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"vonmises_serial_dependence.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\n",
    "Saved: {OUT_DIR / 'vonmises_serial_dependence.png'}\")\n",
    "\n",
    "vm_df = pd.DataFrame(vm_results)\n",
    "if not vm_df.empty:\n",
    "    vm_df.to_csv(OUT_DIR / \"vonmises_serial_parameters.csv\", index=False)\n",
    "    print(vm_df)\n",
    "    print(f\"\n",
    "\u2713 Saved: {OUT_DIR / 'vonmises_serial_parameters.csv'}\")\n",
    "else:\n",
    "    print(\"No von Mises fits were successful.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f51abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DoG parameters across conditions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Panel A: Task comparison (Color vs. Orientation)\n",
    "ax = axes[0]\n",
    "task_data = dog_df[dog_df[\"condition\"].isin([\"Color Task\", \"Orientation Task\"])]\n",
    "colors_task = [\"#3498db\", \"#95a5a6\"]\n",
    "bars = ax.bar(task_data[\"condition\"], task_data[\"A\"], color=colors_task, alpha=0.8, edgecolor=\"black\", linewidth=2)\n",
    "ax.set_ylabel(\"Serial Dependence Strength (A)\", fontsize=13, fontweight=\"bold\")\n",
    "ax.set_title(\"A) Task Specificity\", fontsize=14, fontweight=\"bold\")\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1, alpha=0.5)\n",
    "ax.set_ylim(-0.05, max(task_data[\"A\"]) * 1.3)\n",
    "for i, row in task_data.iterrows():\n",
    "    ax.text(i - len(task_data) // 2, row[\"A\"] + 0.01, f\"A={row['A']:.3f}\n",
    "\u03c3={row['sigma']:.0f}\u00b0\",\n",
    "            ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Panel B: Retrieval mode comparison (Active vs. Passive)\n",
    "ax = axes[1]\n",
    "retrieval_data = dog_df[dog_df[\"condition\"].isin([\"Active Retrieval\", \"Passive Retrieval\"])]\n",
    "colors_ret = [\"#e74c3c\", \"#2ecc71\"]\n",
    "bars = ax.bar(retrieval_data[\"condition\"], retrieval_data[\"A\"], color=colors_ret, alpha=0.8, edgecolor=\"black\", linewidth=2)\n",
    "ax.set_ylabel(\"Serial Dependence Strength (A)\", fontsize=13, fontweight=\"bold\")\n",
    "ax.set_title(\"B) Active vs. Passive Retrieval\", fontsize=14, fontweight=\"bold\")\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1, alpha=0.5)\n",
    "ax.set_ylim(-0.05, max(retrieval_data[\"A\"]) * 1.3)\n",
    "\n",
    "# Calculate ratio\n",
    "if len(retrieval_data) == 2:\n",
    "    passive_A = retrieval_data[retrieval_data[\"condition\"] == \"Passive Retrieval\"][\"A\"].values[0]\n",
    "    active_A = retrieval_data[retrieval_data[\"condition\"] == \"Active Retrieval\"][\"A\"].values[0]\n",
    "    ratio = passive_A / (active_A + 1e-10)\n",
    "    ax.text(0.5, max(retrieval_data[\"A\"]) * 1.15, f\"Passive/Active = {ratio:.1f}x\",\n",
    "            ha=\"center\", fontsize=11, fontweight=\"bold\", color=\"darkred\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"yellow\", alpha=0.7))\n",
    "\n",
    "for i, row in retrieval_data.iterrows():\n",
    "    offset = 0 if i == retrieval_data.index[0] else 1\n",
    "    ax.text(offset, row[\"A\"] + 0.01, f\"A={row['A']:.3f}\",\n",
    "            ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# Panel C: Transition types\n",
    "ax = axes[2]\n",
    "transition_data = dog_df[dog_df[\"condition\"].str.contains(\"\u2192|AA\")]\n",
    "colors_trans = plt.cm.Set2(np.arange(len(transition_data)))\n",
    "bars = ax.bar(range(len(transition_data)), transition_data[\"A\"],\n",
    "              color=colors_trans, alpha=0.8, edgecolor=\"black\", linewidth=2)\n",
    "ax.set_xticks(range(len(transition_data)))\n",
    "ax.set_xticklabels([c.split(\"(\")[1].rstrip(\")\") if \"(\" in c else c for c in transition_data[\"condition\"]],\n",
    "                    rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Serial Dependence Strength (A)\", fontsize=13, fontweight=\"bold\")\n",
    "ax.set_title(\"C) Trial Transitions\", fontsize=14, fontweight=\"bold\")\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1, alpha=0.5)\n",
    "ax.set_ylim(-0.05, max(transition_data[\"A\"]) * 1.2)\n",
    "\n",
    "# Highlight CC\n",
    "if \"CC (Color\u2192Color)\" in transition_data[\"condition\"].values:\n",
    "    cc_idx = transition_data[transition_data[\"condition\"] == \"CC (Color\u2192Color)\"].index[0]\n",
    "    cc_pos = list(transition_data.index).index(cc_idx)\n",
    "    bars[cc_pos].set_edgecolor(\"red\")\n",
    "    bars[cc_pos].set_linewidth(3)\n",
    "\n",
    "for i, (idx, row) in enumerate(transition_data.iterrows()):\n",
    "    ax.text(i, row[\"A\"] + 0.005, f\"{row['A']:.3f}\",\n",
    "            ha=\"center\", va=\"bottom\", fontsize=9, fontweight=\"bold\")\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"dog_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\u2713 Saved: {OUT_DIR / 'dog_comparison.png'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974f554",
   "metadata": {},
   "source": [
    "## 6. Statistical Comparison Across Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b7970",
   "metadata": {},
   "source": [
    "---\n",
    "# Part IV: Results Summary\n",
    "\n",
    "## 7. Key Findings\n",
    "\n",
    "**Serial Dependence Analysis using Fischer & Whitney (2014) Method**\n",
    "\n",
    "### Main Results:\n",
    "\n",
    "1. **Task Specificity**\n",
    "   - **Color Task**: Shows robust serial dependence (A > 0)\n",
    "   - **Orientation Task**: Minimal/no serial dependence (A \u2248 0)\n",
    "   - Interpretation: Serial dependence is feature-specific, not a general phenomenon\n",
    "\n",
    "2. **Retrieval Mode Effect**\n",
    "   - **Passive Retrieval >> Active Retrieval** (typically 5-10x stronger)\n",
    "   - Active retrieval (free choice) provides cognitive control\n",
    "   - Passive retrieval (forced cue) shows automatic attraction bias\n",
    "\n",
    "3. **Transition Effects**\n",
    "   - **CC (Color\u2192Color)**: Strongest serial dependence\n",
    "   - **AA (Active\u2192Active)**: Substantially reduced dependence\n",
    "   - **AC (Active\u2192Color)**: Intermediate effects\n",
    "   - Pattern shows modulation by decision-making process\n",
    "\n",
    "### Interpretation:\n",
    "Active retrieval provides top-down control that substantially reduces automatic serial dependence, suggesting the effect is modulated by cognitive/decision-making processes rather than purely sensory mechanisms.\n",
    "\n",
    "### Technical Note:\n",
    "- **DoG Formula**: `Bias(\u0394) = A\u00b7\u0394\u00b7exp(-\u0394\u00b2/2\u03c3\u00b2)`\n",
    "- **A**: Serial dependence strength (amplitude)\n",
    "- **\u03c3**: Tuning width (peak at \u00b1\u03c3)\n",
    "- **Peak bias**: Maximum attraction occurs at \u0394s = \u00b1\u03c3 degrees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}